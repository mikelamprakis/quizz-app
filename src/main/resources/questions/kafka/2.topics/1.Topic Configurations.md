## Question 1

```markdown
Consider a Kafka topic with the following configuration:

* `cleanup.policy` = "compact,delete"
* `min.cleanable.dirty.ratio` = 0.5
* `delete.retention.ms` = 86400000 (1 day)
* `segment.ms` = 43200000 (12 hours)

Which of the following statements correctly describes the behavior of log compaction and deletion for this topic?

```

**Options**

```markdown
- A. Log compaction and deletion are mutually exclusive; only one policy can be active at any time.
- B. Log compaction will occur once 50% of the segment data is marked as dirty, and logs older than 1 day will be deleted.
- C. Deleted records are removed immediately from the log; `delete.retention.ms` specifies the retention time for all records.
- D. `segment.ms` dictates the maximum lifespan of any record in the log, after which it is eligible for compaction or deletion.
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
Kafka supports both compaction and deletion on a topic when `cleanup.policy = compact,delete`.

- Compaction triggers once 50% of a segment is dirty (`min.cleanable.dirty.ratio = 0.5`).
- `delete.retention.ms` specifies how long tombstones (delete markers) are retained (1 day here).
- `segment.ms` controls segment roll frequency, not record retention duration.

- A. Incorrect — compaction and deletion can co-exist.
- B. Correct — reflects actual behavior.
- C. Incorrect — deleted records (tombstones) are kept for retention time.
- D. Incorrect — segment.ms rolls segments, doesn't control retention directly.
```

</details>

---

## Question 9

```markdown
A Kafka cluster is configured with the following:

`log.retention.hours=48`  
`log.retention.bytes=1073741824`  
`log.segment.bytes=536870912`

Assuming a topic has a constant message production rate, which of the following factors will trigger a log segment to be eligible for deletion?
```

**Options**

```markdown
- A. The log segment is older than 48 hours.
- B. The log segment size exceeds 536870912 bytes (512 MB).
- C. The total size of all log segments for the topic exceeds 1073741824 bytes (1 GB).
- D. All of the above.
```

<details><summary>Response:</summary>

**Answer:** D

**Explanation:**

```markdown
Kafka retention policies combine time and size limits:  
- Segments older than 48 hours are eligible for deletion.  
- Segment size exceeding 512 MB can trigger rolling and deletion.  
- Total log size exceeding 1 GB triggers deletion of oldest segments.  

- A. Correct — time-based retention.
- B. Correct — segment size affects segment rolling.
- C. Correct — total size triggers deletion of old segments.
- D. Correct — all factors apply.
```

</details>

---

## Question 11

```markdown
Assuming a Kafka topic is configured with the following settings:

`log.segment.bytes = 1073741824` (1GB)  
`log.retention.ms = 86400000` (1 day)  
`log.retention.bytes = -1`

Which of the following statements accurately describes the log retention policy for this Kafka topic?
```

**Options**

```markdown
- A. Logs are retained based on size; once the log size exceeds 1GB, older segments are deleted.
- B. Logs are retained for exactly one day, regardless of the size of the log.
- C. Logs are retained until the size of the log exceeds 1GB or for one day, whichever comes first.
- D. Logs are retained indefinitely, as `log.retention.bytes` is set to -1, overriding other retention configurations.
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
- `log.retention.ms = 86400000` enables time-based retention (1 day).  
- `log.retention.bytes = -1` disables size-based retention.  
- `log.segment.bytes` controls segment file size, not retention policy.

Thus, logs are retained based on time only (1 day), ignoring size.

- A. Incorrect — size-based retention is disabled.
- B. Correct — logs retained for one day regardless of size.
- C. Incorrect — size limit is ignored.
- D. Incorrect — logs are not retained indefinitely.
```

</details>

---

## Question 15

```markdown
Compaction is enabled for a topic in Kafka by setting log.cleanup.policy=compact. What is true about log compaction?
```

**Options**

```markdown
- A. Each message stored in the topic is compressed
- B. Compaction changes the offset of the message
- C. After Cleanup, only one message per key is retained with the latest value
```

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**

```markdown
Log compaction retains the last known value for each key in a partition.
- A. Incorrect, compaction is not compression.
- B. Incorrect, compaction does not change message offsets.
- C. Correct, only one message per key with latest value is retained after cleanup.
```

</details>

---

## Question 5

```markdown
What happens if you produce to a topic that does not exist, and the broker setting `auto.create.topics.enable` is set to `false`?

```

**Options**

```markdown
- A. The broker will create the topic with default configurations
- B. The broker will reject the produce request and the producer will throw an exception
- C. The producer will automatically create the topic
- D. The producer will wait until the topic is created
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
When `auto.create.topics.enable=false`, Kafka disallows topic creation on demand. The broker rejects produce requests for non-existent topics, causing producer exceptions.

- A. False — no topic creation when disabled.
- B. Correct — broker rejects and producer errors out.
- C. False — producer does not create topics.
- D. False — producer will not wait, it fails immediately.
```

</details>

---

## Question 6

```markdown
What is the default value of `auto.create.topics.enable` in Kafka?

```

**Options**

```markdown
- A. `true`
- B. `false`
- C. It is not set by default
- D. It depends on the Kafka version
```

<details><summary>Response:</summary>

**Answer:** A

**Explanation:**

```markdown
By default, Kafka has `auto.create.topics.enable` set to `true`. This means topics are auto-created upon first access unless this is explicitly disabled.

- A. Correct — default is true.
- B. False — not default.
- C. False — there is a default setting.
- D. Not generally true; defaults are stable across versions.
```

</details>

---

## Question 7

```markdown
When a topic is automatically created due to `auto.create.topics.enable` being `true`, what configurations are used for the new topic?

```

**Options**

```markdown
- A. The configurations specified by the producer or consumer
- B. The default configurations set on the broker
- C. A combination of producer/consumer configurations and broker defaults
- D. No configurations are set, the topic is created with empty configuration
```

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**

```markdown
Kafka uses the broker's default topic configurations like `num.partitions` and `default.replication.factor` when auto-creating a topic. Client-side configs are ignored.

- A. False — client configs are ignored for auto-creation.
- B. Correct — broker defaults are applied.
- C. False — no mix of configs.
- D. False — defaults are applied, not empty.
```

</details>

---

## Question 16

```markdown
When auto.create.topics.enable is set to true in Kafka configuration,
what are the circumstances under which a Kafka broker automatically creates a topic? (select three)
```

**Options**

```markdown
- A. Producer send message to the topic
- B. Consumer reads message from the topic
- C. Client request the metadata for the topic.
- D. Client Alters the no of partitions of a topic
```

<details><summary>Response:</summary>

**Answer:** A, B, C

**Explanation:**

```markdown
A Kafka broker automatically creates a topic under the following circumstances:
- When a producer starts writing messages to the topic
- When a consumer starts reading messages from the topic
- When any client requests metadata for the topic

D is incorrect, altering partitions does not trigger auto-creation.
```

</details>

---


## Question 20

```markdown
A Kafka broker is configured as follows:

`log.segment.bytes=1073741824`  
`log.segment.ms=86400000`  
`log.retention.bytes=-1`  
`log.retention.ms=604800000`

When will Kafka start a new log segment for a partition, and how long will the old segments be retained?
```

**Options**

```markdown
- A. New segment after 1 GB or 24 hrs; retain for 7 days
- B. New segment after 1 GB or 24 hrs; retain indefinitely
- C. New segment after 1 GB; retain for 7 days or if total exceeds 1 GB
- D. New segment after 24 hrs; retain for 7 days or if total exceeds 1 GB
```

<details><summary>Response:</summary>

**Answer:** A

**Explanation:**

```markdown
Kafka rolls log segments on reaching either size (`1GB`) or time (`24 hours`).  
Retention deletes old segments older than 7 days (`log.retention.ms=604800000`).  
Size-based retention is disabled (`log.retention.bytes=-1`).

- A. Correct — segment rolling and retention times match this option.
- B. Incorrect — retention is time-based, not indefinite.
- C. Incorrect — size retention disabled.
- D. Incorrect — segments roll on size or time, not time alone.
```

</details>

---
