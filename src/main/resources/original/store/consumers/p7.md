## Question 7

How does a consumer commit offsets in Kafka?

* A. It directly commits offsets in Zookeeper
* B. It directly sends the message to `__consumer_offsets`
* C. It interacts with the group coordinator broker

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**
Consumers commit offsets by communicating with the group coordinator broker, which manages offset storage in the internal `__consumer_offsets` topic.

</details>

---

## Question 8

To read data from a topic, the following configuration is needed for the consumers:

* A. any broker to connect, and the topic
* B. all brokers, list of topic name and partition
* C. any broker, list of topic name and partition

<details><summary>Response:</summary>

**Answer:** C

**Explanation:**
A consumer can connect to any broker to fetch metadata and receive the topic and partition info. The consumer needs to know the list of topics and partitions to consume from.

</details>

---

## Question 9

A consumer wants to read messages from partitions 0 and 1 of a topic `topic1` using both `subscribe()` and `assign()`. What happens?

* A. This works fine
* B. Throws `IllegalStateException`

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**
You must use either `subscribe()` (for automatic partition assignment) or `assign()` (for manual assignment), not both at the same time.

</details>

---

## Question 10

A consumer sends a request to commit offset 2000. Due to a network issue, the broker doesnâ€™t receive it. The consumer continues and commits offset 3000. What should you do?

* A. Nothing
* B. Add a new consumer
* C. Restart the consumer

<details><summary>Response:</summary>

**Answer:** A

**Explanation:**
The commit of offset 3000 supersedes the earlier 2000 commit. Since the latest offset is committed, no action is needed.

</details>

---

## Question 11

There are 3 producers writing to a topic with 5 partitions. There are 10 consumers in the same consumer group. How many consumers will remain idle?

* A. 3
* B. 5
* C. 10
* D. None

<details><summary>Response:</summary>

**Answer:** B

**Explanation:**
Since there are only 5 partitions, only 5 consumers can be assigned partitions. The other 5 consumers will be idle.

</details>

---

## Question 12

In Kafka consumer metrics, the fetch-rate is high but each fetch is small. How to improve throughput?

* A. Increase `fetch.min.bytes`
* B. Increase `fetch.max.bytes`
* C. Decrease `fetch.max.bytes`
* D. Decrease `fetch.min.bytes`

<details><summary>Response:</summary>

**Answer:** A

**Explanation:**
Increasing `fetch.min.bytes` causes the broker to wait for more data before responding, increasing batch sizes and improving throughput.

</details>

---

## Question 13

A consumer does complex ML processing that takes approximately 6 minutes per record batch and enters rebalances. What to do?

* A. Increase `max.poll.interval.ms` to 600000
* B. Increase `session.timeout.ms` to 600000
* C. Increase `heartbeat.interval.ms` to 600000

<details><summary>Response:</summary>

**Answer:** A

**Explanation:**
`max.poll.interval.ms` controls how long a consumer can go without calling `.poll()` before being considered dead and triggering a rebalance. Increasing it allows longer processing times.

</details>

---